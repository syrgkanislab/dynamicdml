{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression, MultiTaskLassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from econml.grf import CausalForest\n",
    "from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "from snmm import get_linear_model_reg, get_linear_multimodel_reg\n",
    "from snmm import get_model_reg, get_multimodel_reg\n",
    "from snmm import get_poly_model_reg, get_poly_multimodel_reg\n",
    "from snmm import SNMMDynamicDML, HeteroSNMMDynamicDML\n",
    "from blip import BlipSpec, SimpleHeteroBlipSpec, SimpleBlipSpec, true_param_parse\n",
    "from hetero_utils import WeightedModelFinal, LinearModelFinal, Ensemble, GCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic DML for Structural Nested Mean Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi = False\n",
    "train_test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real dataL Job Corps training program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('JC.csv')\n",
    "df = df.rename(columns={'Unnamed: 0':'id'}).reset_index().drop('index', axis=1).set_index(['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_cols = list(df.columns[1:29])\n",
    "x1_cols = ['everwkdy1', 'earnq4', 'earnq4mis', 'pworky1', 'health12'] #list(df.columns[29:36])\n",
    "t0_cols = df.columns[[36]]\n",
    "t1_cols = df.columns[[37]]\n",
    "y_col = df.columns[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x0_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_cols_cont = ['age', 'educ', 'mwearn', 'hhsize', 'educmum', 'educdad', 'welfarechild']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[x0_cols_cont] = StandardScaler().fit_transform(df[x0_cols_cont])\n",
    "df[x1_cols] = StandardScaler().fit_transform(df[x1_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['educmum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[y_col].values\n",
    "X = {0: df[x0_cols], 1: df[x1_cols], 'het': df[x0_cols]}\n",
    "T = {0: df[t0_cols].values, 1: df[t1_cols].values}\n",
    "m = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for semi-synthetic outcomes\n",
    "if semi:\n",
    "    y = (1 + X[0]['educ'].values) * T[0].flatten()\n",
    "    y += (1 + X[0]['mwearn'].values + X[0]['educ'].values * T[0].flatten()) * T[1].flatten() \n",
    "    y += X[0]['educ'].values + X[0]['health'].values\n",
    "    y += np.random.normal(0, 1, size=(y.shape[0],))\n",
    "    def true_effect_fn(t, X, T):\n",
    "        return (1 + X[0]['educ'].values) if t == 0 else (1 + X[0]['mwearn'].values + X[0]['educ'].values * T[0].flatten())\n",
    "    true_policy_delta = np.mean(true_effect_fn(0, X, T) + true_effect_fn(1, X, T))\n",
    "    true_policy = true_policy_delta + np.mean(X[0]['educ'].values + X[0]['health'].values)\n",
    "    cols = ['educ', 'mwearn']\n",
    "else:\n",
    "    true_policy, true_policy_delta = 0, 0\n",
    "    def true_effect_fn(t, X, T):\n",
    "        return np.zeros(X[0].shape[0])\n",
    "    cols = ['mwearn', 'mwearn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = ['age', 'educ', 'educmum', 'educdad']\n",
    "# X[0] = pd.get_dummies(X[0], columns=cat)\n",
    "# X[0] = pd.concat([X[0], df[cat]], axis=1)\n",
    "# x0_cols = list(X[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if train_test:\n",
    "    Ttest = {}\n",
    "    Xtest = {}\n",
    "    (y, ytest, T[0], Ttest[0], T[1], Ttest[1],\n",
    "     X[0], Xtest[0], X[1], Xtest[1], X['het'], Xtest['het']) = train_test_split(y, T[0], T[1], X[0], X[1], X['het'],\n",
    "                                                                                test_size=.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BlipSpec(heterogeneity=True, lags=True, lag_heterogeneity=True).fit(X, T)\n",
    "phi = bs.phi\n",
    "phi_names = bs.phi_names\n",
    "\n",
    "def pi(t, X, T):\n",
    "    return np.ones(T[t].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate High-Dimensional Linear Blip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = SNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                     model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False),\n",
    "                     model_final_fn=lambda: LassoCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.policy_value_)\n",
    "print(true_policy)\n",
    "print(est.policy_delta_simple_)\n",
    "print(true_policy_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = {}\n",
    "for t in range(m):\n",
    "    print(f'Period {t} effects')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        sig[t] = np.abs(est.psi_[t]) > 0.01\n",
    "        display(est.param_summary(t, coef_thr=0.01).summary_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Selection Inference (not unbiased): Low Dimensional Blip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_sub(t, X, T, Tt):\n",
    "    return phi(t, X, T, Tt)[:, sig[t]]\n",
    "\n",
    "def phi_names_sub(t):\n",
    "    return np.array(phi_names(t))[sig[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sub = SNMMDynamicDML(m=m, phi=phi_sub, phi_names_fn=phi_names_sub,\n",
    "                         model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False), #lambda X, y: get_model_reg(X, y, degrees=[1, 2]),\n",
    "                         model_final_fn=lambda: LinearRegression(),\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sub.fit(Xtest, Ttest, ytest, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.policy_value_)\n",
    "print(true_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(m):\n",
    "    print(f'Period {t} effects')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        display(est_sub.param_summary(t).summary_frame(alpha=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Delta compared to all zero\n",
    "\n",
    "For simple phi, where the structural parameters don't change dependent on the target, we can do sth very simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.policy_delta_simple_)\n",
    "print(true_policy_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For complex phi we need to re-run the estimation for base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_sub.fit_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deltapi, deltapierr = est_sub.policy_delta_complex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(deltapi, deltapierr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Heterogeneity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = SimpleBlipSpec().fit(X, T)\n",
    "bs = BlipSpec(heterogeneity=False, lags=False, lag_heterogeneity=False).fit(X, T)\n",
    "phi = bs.phi\n",
    "phi_names = bs.phi_names\n",
    "\n",
    "def pi(t, X, T):\n",
    "    return np.ones(T[t].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_true_v_est(effects, X, T, cols, mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(X[0].shape[0]) > 0\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    error = effects[0][mask, 0] - true_effect_fn(0, X, T).flatten()[mask]\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    plt.title(f'period 0: rmse={rmse:.3f}')\n",
    "    if semi:\n",
    "        plt.scatter(X[0][cols[0]].values[mask], effects[0][mask], label='est')\n",
    "        plt.scatter(X[0][cols[0]].values[mask], true_effect_fn(0, X, T)[mask], label='true')\n",
    "    else:\n",
    "        sns.regplot(x=X[0][cols[0]].values[mask], y=effects[0][mask])\n",
    "    plt.xlabel(cols[0])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pred = effects[1][mask, 0]\n",
    "    if effects[1].shape[1] == 2:\n",
    "        pred = pred + effects[1][mask, 1] * T[0][mask].flatten() \n",
    "    error = pred - true_effect_fn(1, X, T).flatten()[mask]\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    plt.title(f'period 1: rmse={rmse:.3f}')\n",
    "    if semi:\n",
    "        plt.scatter(X[0][cols[1]].values[mask], pred, label='est')\n",
    "        plt.scatter(X[0][cols[1]].values[mask], true_effect_fn(1, X, T)[mask], label='true')\n",
    "    else:\n",
    "        eff = effects[1][mask]\n",
    "        for t in range(eff.shape[1]):\n",
    "            sns.regplot(x=X[0][cols[1]][mask], y=eff[:, t])\n",
    "    plt.xlabel(cols[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def importances(mdl):\n",
    "    if hasattr(mdl, 'feature_importances_'):\n",
    "        return pd.DataFrame({'name': X['het'].columns, \n",
    "                             'importance': mdl.feature_importances_})\n",
    "    else:\n",
    "        if not (len(mdl.coef_) == len(X['het'].columns) + 1):\n",
    "            return None\n",
    "        return pd.DataFrame({'name': X['het'].columns, \n",
    "                             'importance': mdl.coef_[1:]})\n",
    "\n",
    "def plot_top_k_ensemble_importances(het_est, n_models):\n",
    "    \n",
    "    for t in range(m):\n",
    "        models = het_est.models_[t].model_.models_\n",
    "        weights = het_est.models_[t].model_.weights\n",
    "        inds = np.argsort(weights)[::-1][:n_models]\n",
    "        rows = int(np.floor(np.sqrt(n_models)))\n",
    "        cols = int(np.ceil(n_models / rows))\n",
    "        plt.figure(figsize=(25, 5 * rows))\n",
    "        for it, (weight, mdl) in enumerate(zip(weights[inds], np.array(models)[inds])):\n",
    "            impdf = importances(mdl)\n",
    "            if impdf is not None:\n",
    "                plt.subplot(rows, cols, it + 1)\n",
    "                sns.barplot(y=impdf['name'], x=impdf['importance'])\n",
    "                plt.title(mdl.__repr__()[:10] + f', weight={weight:.3f}')\n",
    "        plt.suptitle(f'Period {t}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define multiple final heterogeneous dynamic effect models\n",
    "\n",
    "Causal forests fit a forest for $\\theta(X)$, minimizing $E[(y - \\theta(X)'T)^2]$.\n",
    "\n",
    "For uni-variate blip model feature maps, any ML model that accepts sample weights can be used, since we can re-write it as: $E[T^2 (y/T - theta(X))^2]$, turning the problem into weighted square loss minimization. We provide the `WeightedModelFinal` wrapper that performs this transformation and wraps any ML model.\n",
    "\n",
    "For linear models, i.e. $\\theta(X) = \\theta'\\psi(X)$, then we can re-write this as a simple linear regression problem over the cross product of the blip feature map $\\phi$ and the heterogeneous effect feature map $\\psi$. We provide the `LinearModelFinal` wrapper that performs this transormations and wraps any linear model and heterogeneous effect feature map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_gen = lambda ms, md, mvl, fr: lambda: CausalForest(n_estimators=1000,\n",
    "                                                    max_depth=md,\n",
    "                                                    min_samples_leaf=ms,\n",
    "                                                    min_balancedness_tol=0.45,\n",
    "                                                    max_samples=fr,\n",
    "                                                    inference=False,\n",
    "                                                    min_var_fraction_leaf=mvl,\n",
    "                                                    min_var_leaf_on_val=True,\n",
    "                                                    random_state=123)\n",
    "linear_gen = lambda: LinearModelFinal(StatsModelsLinearRegression(fit_intercept=False),\n",
    "                                    lambda x: x)\n",
    "lasso_gen = lambda: LinearModelFinal(LassoCV(fit_intercept=False, random_state=123),\n",
    "                                    lambda x: x)\n",
    "polylasso_gen = lambda: LinearModelFinal(LassoCV(fit_intercept=False, random_state=123),\n",
    "                                         lambda x: Pipeline([('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                                                             ('sc', StandardScaler())]).fit_transform(x))\n",
    "rf_gen = lambda ms, md: lambda: WeightedModelFinal(RandomForestRegressor(n_estimators=100,\n",
    "                                                                         min_samples_leaf=ms,\n",
    "                                                                         min_weight_fraction_leaf=0.01,\n",
    "                                                                         max_depth=md,\n",
    "                                                                         random_state=123))\n",
    "lgbm_gen = lambda lr, md: lambda: WeightedModelFinal(lgb.LGBMRegressor(num_leaves=32, n_estimators=5,\n",
    "                                                                       min_child_samples=100,\n",
    "                                                                       learning_rate=lr,\n",
    "                                                                       max_depth=md,\n",
    "                                                                       min_child_weight=0.01,\n",
    "                                                                       random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define model generators for many configurations of the hyperparams of each type of model, each entry in `model_gens` is a function that returns an un-fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gens = [(f'cf{it}', cf_gen(ms, md, mvl, fr))\n",
    "              for it, (ms, md, mvl, fr) in enumerate([(30, 3, 0.01, .8),\n",
    "                                                      (30, 5, 0.01, .8)])]\n",
    "model_gens += [('ols', linear_gen), ('lassocv', lasso_gen), ('2dlassocv', polylasso_gen)]\n",
    "model_gens += [(f'rf{it}', rf_gen(ms, md))\n",
    "               for it, (ms, md) in enumerate([(100, 3), (100, 5)])]\n",
    "model_gens += [(f'lgbm{it}', lgbm_gen(lr, md))\n",
    "               for it, (lr, md) in enumerate([(0.01, 1), (0.01, 3)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GCV` estimator is an estimator that supports the `fit(X, T, y)` interface and performs cross-validation and model selection among all the models in the `model_gens` list. If `ensebmle=True`, it performs soft-max ensembling. If `ensemble=False` it uses the model with the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv_gen = lambda: GCV(model_gens=model_gens, ensemble=True, beta=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est = HeteroSNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                               model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False), #lambda X, y: get_model_reg(X, y, degrees=[1, 2]),\n",
    "                               model_final_fn=gcv_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# het_est.model_final_fn = gcv_gen\n",
    "# het_est.fit_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.models_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.models_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.policy_value_)\n",
    "print(true_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.policy_delta_simple_)\n",
    "print(true_policy_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = het_est.dynamic_effects(X['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, eff[0][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, eff[1][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_v_est(eff, X, T, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_k_ensemble_importances(het_est, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test how each individual model would have performed as a final model if we were to use just that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi:\n",
    "    for name, mgen in model_gens:\n",
    "        print(name, mgen())\n",
    "        het_est.model_final_fn = mgen\n",
    "        het_est.fit_final()\n",
    "        plot_true_v_est(het_est, X, T, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Heterogeneity in Lag Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = SimpleBlipSpec().fit(X, T)\n",
    "bs = BlipSpec(heterogeneity=False, lags=True, lag_heterogeneity=False).fit(X, T)\n",
    "phi = bs.phi\n",
    "phi_names = bs.phi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gens = [(f'cf{it}', cf_gen(ms, md, mvl, fr))\n",
    "              for it, (ms, md, mvl, fr) in enumerate([(30, 3, 0.01, .8),\n",
    "                                                      (30, 5, 0.01, .8)])]\n",
    "model_gens += [('ols', linear_gen), ('lassocv', lasso_gen), ('2dlassocv', polylasso_gen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv_gen = lambda: GCV(model_gens=model_gens, ensemble=True, beta=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est2 = HeteroSNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                                model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False), #lambda X, y: get_model_reg(X, y, degrees=[1, 2]),\n",
    "                                model_final_fn=gcv_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est2.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est2.models_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est2.models_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est2.policy_value_)\n",
    "print(true_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est2.policy_delta_simple_)\n",
    "print(true_policy_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff2 = het_est2.dynamic_effects(X['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, eff2[0][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, eff2[1][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, eff2[1][:, 1])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_v_est(eff2, X, T, cols, mask=(T[0].flatten()==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_v_est(eff2, X, T, cols, mask=(T[0].flatten()==0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_v_est(eff2, X, T, cols, mask=(T[0].flatten()==1) & (X[0]['educ'] > -.1) & (X[0]['educ'] <.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est2.fit_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est2.policy_delta_complex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_eff2 = het_est2.base_dynamic_effects(X['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, base_eff2[0][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, base_eff2[1][:, 0])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X['het'].values, base_eff2[1][:, 1])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree, feature_names=X['het'].columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_v_est(base_eff2, X, T, cols, mask=(T[0].flatten()==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating heterogeneity finding on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efftest = het_est2.dynamic_effects(Xtest['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "newXtest = copy.deepcopy(Xtest)\n",
    "newXtest['het'] = pd.DataFrame({'cate0': efftest[0][:, 0] - np.mean(efftest[0][:, 0]), \n",
    "                                'cate11': efftest[1][:, 0] - np.mean(efftest[1][:, 0]),\n",
    "                                'cate10': efftest[1][:, 1] - np.mean(efftest[1][:, 1])},\n",
    "                               index=Xtest['het'].index)\n",
    "newXtest['het']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "distill_vals = {}\n",
    "distill = DecisionTreeRegressor(max_depth=1, min_samples_leaf=1000).fit(X['het'].values, eff2[0][:, 0])\n",
    "distill_vals['cate0'] = distill.predict(newXtest[0].values[:, :X['het'].shape[1]])\n",
    "distill = DecisionTreeRegressor(max_depth=1, min_samples_leaf=1000).fit(X['het'].values, eff2[1][:, 0])\n",
    "distill_vals['cate11'] = distill.predict(newXtest[0].values[:, :X['het'].shape[1]])\n",
    "distill = DecisionTreeRegressor(max_depth=1, min_samples_leaf=1000).fit(X['het'].values, eff2[1][:, 1])\n",
    "distill_vals['cate10'] = distill.predict(newXtest[0].values[:, :X['het'].shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "newXtest = copy.deepcopy(Xtest)\n",
    "newXtest['het'] = pd.get_dummies(pd.DataFrame(distill_vals, index=Xtest['het'].index),\n",
    "                                 columns=['cate0', 'cate10', 'cate11'], drop_first=True)\n",
    "newXtest['het'].columns = ['cate0', 'cate10', 'cate11']\n",
    "newXtest['het']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.prod(newXtest['het'], axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "newXtest = copy.deepcopy(Xtest)\n",
    "distill_vals = {}\n",
    "distill = DecisionTreeRegressor(max_depth=2, min_samples_leaf=1000).fit(X['het'].values,\n",
    "                                                                        np.hstack([eff2[0][:, [0]], eff2[1]]))\n",
    "plot_tree(distill, feature_names=X['het'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_vals['cate'] = distill.apply(newXtest['het'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill.predict(newXtest['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "newXtest = copy.deepcopy(Xtest)\n",
    "newXtest['het'] = pd.get_dummies(pd.DataFrame(distill_vals, index=Xtest['het'].index),\n",
    "                                 columns=['cate'], drop_first=False)\n",
    "newXtest['het']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newXtest[0] = pd.concat([newXtest[0], newXtest['het']], axis=1)\n",
    "newXtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.utilities import cross_product\n",
    "\n",
    "class SimpleHeteroBlipSpec(BlipSpec):\n",
    "\n",
    "    def phi(self, t, X, T, Tt):\n",
    "        if t==1:\n",
    "            return np.hstack([Tt, cross_product(Tt, X['het'][['cate11']].values),\n",
    "                              cross_product(Tt, T[t-1]),\n",
    "                              cross_product(Tt, T[t-1], X['het'][['cate10']].values)])\n",
    "        else:\n",
    "            return np.hstack([Tt, cross_product(Tt, X['het'][['cate0']].values)])\n",
    "\n",
    "    def phi_names(self, t):\n",
    "        out = [f't[{x}]' for x in range(self.n_treatments[t])]\n",
    "        if t==1:\n",
    "            out += [f't[{x}]*x0[cate11]' for x in range(self.n_treatments[t])]\n",
    "            out += [f't[{x}]*lagt[{y}]' for y in range(self.n_treatments[t-1]) for x in range(self.n_treatments[t])]\n",
    "            out += [f't[{x}]*lagt[{y}]*x0[cate10]' for y in range(self.n_treatments[t])\n",
    "                                                for x in range(self.n_treatments[t])]\n",
    "        else:\n",
    "            out += [f't[{x}]*x0[cate0]' for x in range(self.n_treatments[t])]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = SimpleHeteroBlipSpec().fit(Xtest, Ttest)\n",
    "phi = bs.phi\n",
    "phi_names = bs.phi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_test = SNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                         model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False), #lambda X, y: get_model_reg(X, y, degrees=[1, 2]),\n",
    "                         model_final_fn=lambda: LinearRegression(),\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_test.fit(newXtest, Ttest, ytest, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(m):\n",
    "    print(f'Period {t} effects')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        display(est_test.param_summary(t).summary_frame(alpha=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_test.policy_delta_simple_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = SimpleBlipSpec().fit(X, T)\n",
    "bs = BlipSpec(heterogeneity=False, lags=True, lag_heterogeneity=False).fit(X, T)\n",
    "phi = bs.phi\n",
    "phi_names = bs.phi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est_test = HeteroSNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                                model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=2, interaction_only=False), #lambda X, y: get_model_reg(X, y, degrees=[1, 2]),\n",
    "                                model_final_fn=lambda: LinearModelFinal(StatsModelsLinearRegression(fit_intercept=False),\n",
    "                                                                        lambda x: x,\n",
    "                                                                        fit_cate_intercept=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est_test.fit(newXtest, Ttest, ytest, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est_test.param_summary(0).summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est_test.param_summary(1).summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                      model_reg_fn=lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False),\n",
    "                      model_final_fn=lambda: LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.fit(newXtest, Ttest, ytest, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.param_summary(0).summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.param_summary(1).summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
