{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"0\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://ictd2016.files.wordpress.com/2016/04/microsoft-research-logo-copy.jpg\" style=\"width 30px;\" />\n",
    "             </td>\n",
    "        <td>\n",
    "            <img src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/MSR-ALICE-HeaderGraphic-1920x720_1-800x550.jpg\" style=\"width 100px;\"/></td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Double Machine Learning: Use Cases and Examples\n",
    "\n",
    "Dynamic DoubleML is an extension of the Double ML approach for treatments assigned sequentially over time periods. This estimator will account for treatments that can have causal effects on future outcomes. For more details, see [this paper](https://arxiv.org/abs/2002.07285) or the [EconML docummentation](https://econml.azurewebsites.net/).\n",
    "\n",
    "For example, the Dynamic DoubleML could be useful in estimating the following causal effects:\n",
    "* the effect of investments on revenue at companies that receive investments at regular intervals ([see more](https://arxiv.org/abs/2103.08390))\n",
    "* the effect of prices on demand in stores where prices of goods change over time\n",
    "* the effect of income on health outcomes in people who receive yearly income\n",
    "\n",
    "The preferred data format is balanced panel data. Each panel corresponds to one entity (e.g. company, store or person) and the different rows in a panel correspond to different time points. Example:\n",
    "\n",
    "||Company|Year|Features|Investment|Revenue|\n",
    "|---|---|---|---|---|---|\n",
    "|1|A|2018|...|\\$1,000|\\$10,000|\n",
    "|2|A|2019|...|\\$2,000|\\$12,000|\n",
    "|3|A|2020|...|\\$3,000|\\$15,000|\n",
    "|4|B|2018|...|\\$0|\\$5,000|\n",
    "|5|B|2019|...|\\$100|\\$10,000|\n",
    "|6|B|2020|...|\\$1,200|\\$7,000|\n",
    "|7|C|2018|...|\\$1,000|\\$20,000|\n",
    "|8|C|2019|...|\\$1,500|\\$25,000|\n",
    "|9|C|2020|...|\\$500|\\$15,000|\n",
    "\n",
    "(Note: when passing the data to the DynamicDML estimator, the \"Company\" column above corresponds to the `groups` argument at fit time. The \"Year\" column above should not be passed in as it will be inferred from the \"Company\" column)\n",
    "\n",
    "If group memebers do not appear together, it is assumed that the first instance of a group in the dataset corresponds to the first period of that group, the second instance of the group corresponds to the second period, etc. Example:\n",
    "\n",
    "||Company|Features|Investment|Revenue|\n",
    "|---|---|---|---|---|\n",
    "|1|A|...|\\$1,000|\\$10,000|\n",
    "|2|B|...|\\$0|\\$5,000\n",
    "|3|C|...|\\$1,000|\\$20,000|\n",
    "|4|A|...|\\$2,000|\\$12,000|\n",
    "|5|B|...|\\$100|\\$10,000|\n",
    "|6|C|...|\\$1,500|\\$25,000|\n",
    "|7|A|...|\\$3,000|\\$15,000|\n",
    "|8|B|...|\\$1,200|\\$7,000|\n",
    "|9|C|...|\\$500|\\$15,000|\n",
    "\n",
    "In this dataset, 1<sup>st</sup> row corresponds to the first period of group `A`, 4<sup>th</sup> row corresponds to the second period of group `A`, etc.\n",
    "\n",
    "In this notebook, we show the performance of the DynamicDML on synthetic and observational data. \n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "1. [Example Usage with Average Treatment Effects](#1.-Example-Usage-with-Average-Treatment-Effects)\n",
    "2. [Example Usage with Heterogeneous Treatment Effects](#2.-Example-Usage-with-Heterogeneous-Treatment-Effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "from econml.dynamic.dml import DynamicDML\n",
    "from econml.tests.dgp import DynamicPanelDGP, add_vlines\n",
    "\n",
    "# Helper imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV, MultiTaskLassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Example Usage with Average Treatment Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 DGP\n",
    "\n",
    "We consider a data generating process from a markovian treatment model. \n",
    "\n",
    "In the example bellow, $T_t\\rightarrow$ treatment(s) at time $t$, $Y_t\\rightarrow$outcome at time $t$, $X_t\\rightarrow$ features and controls at time $t$ (the coefficients $e, f$ will pick the features and the controls).\n",
    "\\begin{align}\n",
    "    X_t =& (\\pi'X_{t-1} + 1) \\cdot A\\, T_{t-1} + B X_{t-1} + \\epsilon_t\\\\\n",
    "    T_t =& \\gamma\\, T_{t-1} + (1-\\gamma) \\cdot D X_t + \\zeta_t\\\\\n",
    "    Y_t =& (\\sigma' X_{t} + 1) \\cdot e\\, T_{t} + f X_t + \\eta_t\n",
    "\\end{align}\n",
    "\n",
    "with $X_0, T_0 = 0$ and $\\epsilon_t, \\zeta_t, \\eta_t \\sim N(0, \\sigma^2)$. Moreover, $X_t \\in R^{n_x}$, $B[:, 0:s_x] \\neq 0$ and $B[:, s_x:-1] = 0$, $\\gamma\\in [0, 1]$, $D[:, 0:s_x] \\neq 0$, $D[:, s_x:-1]=0$, $f[0:s_x]\\neq 0$, $f[s_x:-1]=0$. We draw a single time series of samples of length $n\\_panels \\cdot n\\_periods$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DGP parameters\n",
    "np.random.seed(123)\n",
    "n_panels = 5000 # number of panels\n",
    "n_periods = 2 # number of time periods in each panel\n",
    "n_treatments = 1 # number of treatments in each period\n",
    "n_x = 100 # number of features + controls\n",
    "s_x = 10 # number of controls (endogeneous variables)\n",
    "s_t = 10 # treatment support size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "dgp = DynamicPanelDGP(n_periods, n_treatments, n_x).create_instance(\n",
    "            s_x, random_seed=12345, autoreg=1.0)\n",
    "Y, T, X, W, groups = dgp.observational_data(n_panels, s_t=s_t, random_seed=12345)\n",
    "true_effect = dgp.true_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = DynamicDML(\n",
    "    model_y=LassoCV(cv=3, max_iter=1000), \n",
    "    model_t=MultiTaskLassoCV(cv=3, max_iter=1000), \n",
    "    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(Y, T, X=None, W=W, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average treatment effect of all periods on last period for unit treatments\n",
    "print(f\"Average effect of default policy: {est.ate():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of target policy over baseline policy\n",
    "# Must specify a treatment for each period\n",
    "baseline_policy = np.zeros((1, n_periods * n_treatments))\n",
    "target_policy = np.ones((1, n_periods * n_treatments))\n",
    "eff = est.effect(T0=baseline_policy, T1=target_policy)\n",
    "print(f\"Effect of target policy over baseline policy: {eff[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period treatment effects + interpretation\n",
    "for i, theta in enumerate(est.intercept_.reshape(-1, n_treatments)):\n",
    "    print(f\"Marginal effect of a treatments in period {i+1} on period {n_periods} outcome: {theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period treatment effects with confidence intervals\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ints = est.intercept__interval(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plotting boilerplate code\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.errorbar(np.arange(n_periods*n_treatments)-.04, est.intercept_, yerr=(conf_ints[1] - est.intercept_,\n",
    "                                                    est.intercept_ - conf_ints[0]), fmt='o', label='DynamicDML')\n",
    "plt.errorbar(np.arange(n_periods*n_treatments), true_effect.flatten(), fmt='o', alpha=.6, label='Ground truth')\n",
    "for t in np.arange(1, n_periods):\n",
    "    plt.axvline(x=t * n_treatments - .5, linestyle='--', alpha=.4)\n",
    "plt.xticks([t * n_treatments - .5 + n_treatments/2 for t in range(n_periods)],\n",
    "           [\"$\\\\theta_{}$\".format(t) for t in range(n_periods)])\n",
    "plt.gca().set_xlim([-.5, n_periods*n_treatments - .5])\n",
    "plt.ylabel(\"Effect\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Example Usage with Heterogeneous Treatment Effects on Time-Invariant Unit Characteristics\n",
    "\n",
    "We can also estimate treatment effect heterogeneity with respect to the value of some subset of features $X$ in the initial period. Heterogeneity is currently only supported with respect to such initial state features. This for instance can support heterogeneity with respect to time-invariant unit characteristics. In that case you can simply pass as $X$ a repetition of some unit features that stay constant in all periods. You can also pass time-varying features, and their time varying component will be used as a time-varying control. However, heterogeneity will only be estimated with respect to the initial state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional DGP parameters\n",
    "het_strength = .5\n",
    "het_inds = np.arange(n_x - n_treatments, n_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "dgp = DynamicPanelDGP(n_periods, n_treatments, n_x).create_instance(\n",
    "            s_x, hetero_strength=het_strength, hetero_inds=het_inds,\n",
    "            autoreg=1.0, random_seed=1566)\n",
    "Y, T, X, W, groups = dgp.observational_data(n_panels, s_t=s_t, random_seed=1)\n",
    "ate_effect = dgp.true_effect\n",
    "het_effect = dgp.true_hetero_effect[:, het_inds + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = DynamicDML(\n",
    "    model_y=LassoCV(cv=3), \n",
    "    model_t=MultiTaskLassoCV(cv=3),\n",
    "    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(Y, T, X=X, W=W, groups=groups, inference=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average treatment effect for test points\n",
    "X_test = X[np.arange(0, 25, 3)]\n",
    "print(f\"Average effect of default policy:{est.ate(X=X_test):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of target policy over baseline policy\n",
    "# Must specify a treatment for each period\n",
    "baseline_policy = np.zeros((1, n_periods * n_treatments))\n",
    "target_policy = np.ones((1, n_periods * n_treatments))\n",
    "eff = est.effect(X=X_test, T0=baseline_policy, T1=target_policy)\n",
    "print(\"Effect of target policy over baseline policy for test set:\\n\", eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients: intercept is of shape n_treatments*n_periods\n",
    "# coef_ is of shape (n_treatments*n_periods, n_hetero_inds).\n",
    "# first n_treatment rows are from first period, next n_treatment\n",
    "# from second period, etc.\n",
    "est.intercept_, est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals\n",
    "conf_ints_intercept = est.intercept__interval(alpha=0.05)\n",
    "conf_ints_coef = est.coef__interval(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse true parameters in array of shape (n_treatments*n_periods, 1 + n_hetero_inds)\n",
    "# first column is the intercept\n",
    "true_effect_inds = []\n",
    "for t in range(n_treatments):\n",
    "    true_effect_inds += [t * (1 + n_x)] + (list(t * (1 + n_x) + 1 + het_inds) if len(het_inds)>0 else [])\n",
    "true_effect_params = dgp.true_hetero_effect[:, true_effect_inds]\n",
    "true_effect_params = true_effect_params.reshape((n_treatments*n_periods, 1 + het_inds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating intercept and coef_\n",
    "param_hat = np.hstack([est.intercept_.reshape(-1, 1), est.coef_])\n",
    "lower = np.hstack([conf_ints_intercept[0].reshape(-1, 1), conf_ints_coef[0]])\n",
    "upper = np.hstack([conf_ints_intercept[1].reshape(-1, 1), conf_ints_coef[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.errorbar(np.arange(n_periods * (len(het_inds) + 1) * n_treatments) - .04,\n",
    "             param_hat.flatten(), yerr=((upper - param_hat).flatten(),\n",
    "                                        (param_hat - lower).flatten()), fmt='o', label='DynamicDML')\n",
    "plt.errorbar(np.arange(n_periods * (len(het_inds) + 1) * n_treatments),\n",
    "             true_effect_params.flatten(), fmt='*', label='Ground Truth')\n",
    "add_vlines(n_periods, n_treatments, het_inds)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.nuisance_scores_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.nuisance_scores_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Corps Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "\n",
    "df = pd.read_csv('JC.csv')\n",
    "df = df.rename(columns={'Unnamed: 0':'id'}).reset_index().drop('index', axis=1).set_index(['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_cols = list(df.columns[1:29])\n",
    "x1_cols = list(df.columns[29:36])\n",
    "t0_cols = df.columns[[36]]\n",
    "t1_cols = df.columns[[37]]\n",
    "y_col = df.columns[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[y_col]\n",
    "X0 = df[x0_cols]\n",
    "X1 = df[x1_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panelX = np.zeros((X0.shape[0], 2, X0.shape[1] + X1.shape[1]))\n",
    "panelX[:, 0, :X0.shape[1]] = X0.values\n",
    "panelX[:, 1, :X0.shape[1]] = X0.values\n",
    "panelX[:, 1, X0.shape[1]:] = X1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panelT = np.zeros((X0.shape[0], 2, 1))\n",
    "panelT[:, 0, :] = df[t0_cols].values\n",
    "panelT[:, 1, :] = df[t1_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagpanelT = np.zeros((X0.shape[0], 2, 1))\n",
    "lagpanelT[:, 1, :] = panelT[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panelY = np.zeros((X0.shape[0], 2, 1))\n",
    "panelY[:, 1, 0] = df[y_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panelG = np.zeros((X0.shape[0], 2, 1), 'int')\n",
    "panelG[:, 0, 0] = np.arange(X0.shape[0])\n",
    "panelG[:, 1, 0] = np.arange(X0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long(X):\n",
    "    return X.reshape((-1, X.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dynamic.dml import DynamicDML\n",
    "est = DynamicDML(\n",
    "    model_y=LassoCV(cv=3, max_iter=1000), \n",
    "    model_t=LogisticRegressionCV(cv=3, max_iter=2000),\n",
    "    discrete_treatment=True,\n",
    "    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(long(panelY).flatten(), long(panelT).flatten(),\n",
    "        W=np.hstack([long(panelX), long(lagpanelT)]),\n",
    "        groups=long(panelG).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.effect_inference().summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNMM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV, MultiTaskLassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('JC.csv')\n",
    "df = df.rename(columns={'Unnamed: 0':'id'}).reset_index().drop('index', axis=1).set_index(['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_cols = list(df.columns[1:29])\n",
    "x1_cols = list(df.columns[29:36])\n",
    "t0_cols = df.columns[[36]]\n",
    "t1_cols = df.columns[[37]]\n",
    "y_col = df.columns[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['educmum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[y_col].values\n",
    "X = {0: df[x0_cols], 1: df[x1_cols], 'het': df[x0_cols]}\n",
    "T = {0: df[t0_cols].values, 1: df[t1_cols].values}\n",
    "m = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['age', 'educ', 'educmum', 'educdad']\n",
    "X[0] = pd.get_dummies(X[0], columns=cat)\n",
    "X[0] = pd.concat([X[0], df[cat]], axis=1)\n",
    "x0_cols = list(X[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect_params = np.zeros((m, T[0].shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import gen_data\n",
    "m = 2\n",
    "y, X, T, true_effect_params = gen_data(n_periods=m, n_units=10000, n_treatments=2,\n",
    "                                       n_x=10, s_x=2, s_t=2,\n",
    "                                       hetero_strenth=.0, n_hetero_vars=0, autoreg=1.0,\n",
    "                                       instance_seed=13, sample_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['het'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data with heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import gen_data\n",
    "m = 2\n",
    "y, X, T, true_effect_params = gen_data(n_periods=m, n_units=10000, n_treatments=1,\n",
    "                                       n_x=10, s_x=1, s_t=1,\n",
    "                                       hetero_strenth=.5, n_hetero_vars=1, autoreg=1.0,\n",
    "                                       instance_seed=123, sample_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import get_linear_model_reg, get_linear_multimodel_reg\n",
    "from snmm import get_model_reg, get_multimodel_reg\n",
    "from snmm import get_poly_model_reg, get_poly_multimodel_reg\n",
    "from econml.utilities import cross_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_reg_fn = lambda X, y: get_model_reg(X, y, degrees=[1])\n",
    "# multimodel_reg_fn = lambda X, y: get_multimodel_reg(X, y, degrees=[1])\n",
    "# model_reg_fn = get_linear_model_reg\n",
    "# multimodel_reg_fn = get_linear_multimodel_reg\n",
    "model_reg_fn = lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=True)\n",
    "multimodel_reg_fn = lambda X, y: get_poly_multimodel_reg(X, y, degree=1, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_cols11 = list(X[1].columns)\n",
    "het_cols10 = list(X[0].columns)\n",
    "het_cols0 = list(X[0].columns)\n",
    "def phi(t, X, T, Tt):\n",
    "    if t == 1:\n",
    "        return np.hstack([Tt,\n",
    "                          cross_product(Tt, T[t-1]),\n",
    "                          cross_product(Tt, X[t][het_cols11].values),\n",
    "                          cross_product(Tt, X[t-1][het_cols10].values),\n",
    "                          cross_product(Tt, T[t-1], X[t][het_cols11].values),\n",
    "                          cross_product(Tt, T[t-1], X[t-1][het_cols10].values)\n",
    "                         ])\n",
    "    elif t==0:\n",
    "        return np.hstack([Tt, cross_product(Tt, X[t][het_cols0].values)])\n",
    "    raise AttributeError(\"Not valid\")\n",
    "\n",
    "def phi_names(t):\n",
    "    if t == 1:\n",
    "        return ([f't2[{x}]' for x in range(T[1].shape[1])] +\n",
    "                [f't2[{x}]*t1[{y}]' for y in range(T[0].shape[1]) for x in range(T[1].shape[1])] +\n",
    "                [f't2[{x}]*x2[{y}]' for y in het_cols11 for x in range(T[1].shape[1])] + \n",
    "                [f't2[{x}]*x1[{y}]' for y in het_cols10 for x in range(T[1].shape[1])] +\n",
    "                [f't2[{x}]*t1[{y}]*{z}' for z in het_cols11 for y in range(T[0].shape[1])\n",
    "                                        for x in range(T[1].shape[1])] + \n",
    "                [f't2[{x}]*t1[{y}]*{z}' for z in het_cols10 for y in range(T[0].shape[1])\n",
    "                                        for x in range(T[1].shape[1])]\n",
    "               )\n",
    "    elif t == 0:\n",
    "        return ([f't1[{x}]' for x in range(T[1].shape[1])] + \n",
    "                [f't1[{x}]*{y}' for y in het_cols0 for x in range(T[1].shape[1])])\n",
    "    raise AttributeError(\"Not valid\")\n",
    "\n",
    "def pi(t, X, T):\n",
    "    return np.ones(T[t].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate High-Dimensional Linear Blip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import SNMMDynamicDML\n",
    "\n",
    "est = SNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                     model_reg_fn=model_reg_fn,\n",
    "                     model_final_fn=lambda: LassoCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.policy_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = {}\n",
    "for t in range(m):\n",
    "    print(f'Period {t} effects {true_effect_params[t]}')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        sig[t] = np.abs(est.psi_[t]) > 0.01\n",
    "        display(est.param_summary(t, coef_thr=0.01).summary_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Selection Inference (not unbiased): Low Dimensional Blip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_sub(t, X, T, Tt):\n",
    "    return phi(t, X, T, Tt)[:, sig[t]]\n",
    "\n",
    "def phi_names_sub(t):\n",
    "    return np.array(phi_names(t))[sig[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "est_sub = SNMMDynamicDML(m=m, phi=phi_sub, phi_names_fn=phi_names_sub,\n",
    "                         model_reg_fn=lambda X, y: get_model_reg(X, y, degrees=[1]),\n",
    "                         model_final_fn=lambda: LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sub.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.policy_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(m):\n",
    "    print(f'Period {t} effects {true_effect_params[t]}')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        display(est_sub.param_summary(t).summary_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Delta compared to all zero\n",
    "\n",
    "For simple phi, where the structural parameters don't change dependent on the target, we can do sth very simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.policy_delta_simple_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For complex phi we need to re-run the estimation for base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sub.fit_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltapi, deltapierr = est_sub.policy_delta_complex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deltapi, deltapierr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Dynamic Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_sub.fit_opt(X, T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.opt_policy_delta_simple_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_sub.opt_policy_delta_complex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(m):\n",
    "    print(f'Period {t} effects {true_effect_params[t]}')\n",
    "    with pd.option_context(\"precision\", 3):\n",
    "        display(est_sub.opt_param_summary(t).summary_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_reg_fn = lambda X, y: get_model_reg(X, y, degrees=[1])\n",
    "# multimodel_reg_fn = lambda X, y: get_multimodel_reg(X, y, degrees=[1])\n",
    "# model_reg_fn = get_linear_model_reg\n",
    "# multimodel_reg_fn = get_linear_multimodel_reg\n",
    "model_reg_fn = lambda X, y: get_poly_model_reg(X, y, degree=1, interaction_only=False)\n",
    "multimodel_reg_fn = lambda X, y: get_poly_multimodel_reg(X, y, degree=1, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(t, X, T, Tt):\n",
    "    if t == 1:\n",
    "        return np.hstack([Tt, cross_product(Tt, T[t-1])])\n",
    "    elif t==0:\n",
    "        return np.hstack([Tt])\n",
    "    raise AttributeError(\"Not valid\")\n",
    "\n",
    "def phi_names(t):\n",
    "    if t == 1:\n",
    "        return ([f't2[{x}]' for x in range(T[1].shape[1])] +\n",
    "                [f't2[{x}]*t1[{y}]' for y in range(T[0].shape[1]) for x in range(T[1].shape[1])])\n",
    "    elif t == 0:\n",
    "        return [f't1[{x}]' for x in range(T[1].shape[1])]\n",
    "    raise AttributeError(\"Not valid\")\n",
    "\n",
    "def pi(t, X, T):\n",
    "    return np.ones(T[t].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import fit_heterogeneous_final, LinearModelFinal\n",
    "from econml.grf import CausalForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression\n",
    "\n",
    "cf_gen = lambda: CausalForest(n_estimators=1000,\n",
    "                              max_depth=3,\n",
    "                              min_samples_leaf=50,\n",
    "                              min_var_fraction_leaf=0.1,\n",
    "                              min_var_leaf_on_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmm import HeteroSNMMDynamicDML\n",
    "\n",
    "het_est = HeteroSNMMDynamicDML(m=m, phi=phi, phi_names_fn=phi_names,\n",
    "                               model_reg_fn=lambda X, y: get_model_reg(X, y, degrees=[1]),\n",
    "                               model_final_fn=cf_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.fit(X, T, y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.policy_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.policy_delta_simple_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "if hasattr(het_est.models_[0], 'feature_importances_'):\n",
    "    for t in range(m):\n",
    "        impdf = het_est.feature_importances_(t)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.barplot(y=impdf['name'], x=impdf['importance'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "if hasattr(het_est.models_[0], 'feature_importances_'):\n",
    "    for t in range(m):\n",
    "        exp = shap.Explainer(het_est.models_[t])\n",
    "        shap_values = exp.shap_values(X['het'])\n",
    "        shap.summary_plot(shap_values, X['het'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit value of baseline policy, for delta estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.fit_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.policy_delta_complex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Dynamic Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.fit_opt(X, T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.pi_star(1, X, T)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(het_est.models_[0], 'linear_model'):\n",
    "    for t in range(m):\n",
    "        print(f'Period {t} effects {true_effect_params[t]}')\n",
    "        display(het_est.opt_param_summary(t).summary_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "if hasattr(het_est.opt_models_[0], 'feature_importances_'):\n",
    "    for t in range(m):\n",
    "        impdf = het_est.opt_feature_importances_(t)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.barplot(y=impdf['name'], x=impdf['importance'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "if hasattr(het_est.opt_models_[0], 'feature_importances_'):\n",
    "    for t in range(m):\n",
    "        exp = shap.Explainer(het_est.opt_models_[t])\n",
    "        shap_values = exp.shap_values(X['het'])\n",
    "        shap.summary_plot(shap_values, X['het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.opt_policy_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.opt_policy_delta_simple_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(het_est.opt_policy_delta_complex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model of heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_gen = lambda: LinearModelFinal(StatsModelsLinearRegression(fit_intercept=False),\n",
    "#                                       lambda x: x)\n",
    "linear_gen = lambda: LinearModelFinal(LassoCV(fit_intercept=False),\n",
    "                                  lambda x: x)\n",
    "het_est.model_final_fn = linear_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_est.fit_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(het_est.models_[0], 'linear_model'):\n",
    "    for t in range(m):\n",
    "        print(f'Period {t} effects {true_effect_params[t]}')\n",
    "        display(het_est.param_summary(t).summary_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import main\n",
    "\n",
    "res = main(n_periods=2, n_units=10000, n_treatments=1, n_x=2, s_x=1, s_t=1,\n",
    "           n_instances=1, n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import main\n",
    "import joblib\n",
    "n_instances = 2\n",
    "n_samples = 8\n",
    "n_periods = 2\n",
    "for n_hetero_vars in [0]:\n",
    "    for n_units in [1000]:\n",
    "        for n_x in [2]:\n",
    "            res = main(n_periods=n_periods, n_units=n_units, n_treatments=1,\n",
    "                       n_x=n_x, s_x=2, s_t=2,\n",
    "                       n_hetero_vars=n_hetero_vars,\n",
    "                       n_instances=n_instances,\n",
    "                       n_samples=n_samples,\n",
    "                       verbose=1)\n",
    "            file = f'n_ins_{n_instances}_n_sam_{n_samples}_n_hetero_vars_{n_hetero_vars}_n_units_{n_units}_n_x_{n_x}.jbl'\n",
    "            joblib.dump(res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import all_experiments\n",
    "all_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing many experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def helper(df, prop):\n",
    "    return df[prop] if prop in df else 0\n",
    "\n",
    "n_instances = 2\n",
    "n_samples = 8\n",
    "n_hetero_vars = 0\n",
    "n_periods = 2\n",
    "n_units = 1000\n",
    "n_x = 2\n",
    "file = f'n_ins_{n_instances}_n_sam_{n_samples}_n_hetero_vars_{n_hetero_vars}_n_units_{n_units}_n_x_{n_x}.jbl'\n",
    "res = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def metrics(truth, point, std):\n",
    "    metrics = {}\n",
    "    metrics['coverage90'] = np.mean((point - 1.645 * std <= truth) & (point + 1.645 * std >= truth))\n",
    "    metrics['coverage95'] = np.mean((point - 1.96 * std <= truth) & (point + 1.96 * std >= truth))\n",
    "    metrics['coverage99'] = np.mean((point - 2.58 * std <= truth) & (point + 2.58 * std >= truth))\n",
    "    metrics['bias'] = np.mean(point - truth)\n",
    "    metrics['rmse'] = np.sqrt(np.mean((point - truth)**2))\n",
    "    metrics['mae'] = np.mean(np.abs(point - truth))\n",
    "    metrics['mape'] = np.mean(np.abs(point - truth) / np.abs(truth))\n",
    "    return metrics\n",
    "\n",
    "summary = {}\n",
    "for instance in range(n_instances):\n",
    "    summary[instance] = {}\n",
    "    for feat in res[instance][0]['true']:\n",
    "        if feat == 'params':\n",
    "            continue\n",
    "        summary[instance][feat] = {}\n",
    "        truth = res[instance][0]['true'][feat]\n",
    "        summary[instance][feat]['true'] = truth\n",
    "        for method in res[instance][0]:\n",
    "            if method == 'true':\n",
    "                continue\n",
    "            if feat in res[instance][0][method]:\n",
    "                summary[instance][feat][method] = {}\n",
    "                point = np.array([res[instance][t][method][feat][0] for t in range(n_samples)])\n",
    "                std = np.array([res[instance][t][method][feat][1] for t in range(n_samples)])\n",
    "                summary[instance][feat][method] = metrics(truth, point, std)\n",
    "    \n",
    "    summary[instance]['params'] = {}\n",
    "    for period in range(n_periods):\n",
    "        summary[instance]['params'][period] = {}\n",
    "        for feat_it, feat in enumerate(res[instance][0]['true']['params'][period].keys()):\n",
    "            if res[instance][0]['true']['params'][period][feat] == 0:\n",
    "                continue\n",
    "            summary[instance]['params'][period][feat] = {}\n",
    "            truth = res[instance][0]['true']['params'][period][feat]\n",
    "            summary[instance]['params'][period][feat]['true'] = truth\n",
    "            for method in res[instance][0]:\n",
    "                if method == 'true':\n",
    "                    continue\n",
    "                point = np.array([helper(res[instance][t][method]['params'][period]['point_estimate'], feat)\n",
    "                                  for t in range(n_samples)])\n",
    "                std = np.array([helper(res[instance][t][method]['params'][period]['stderr'], feat)\n",
    "                                for t in range(n_samples)])\n",
    "                summary[instance]['params'][period][feat][method] = metrics(truth, point, std)\n",
    "                plt.hist(point, label=method)\n",
    "            plt.axvline(x = truth, label='true', color='red')\n",
    "            plt.title(f'period {period}, feat {feat}, instance {instance}')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsummary = {}\n",
    "for feat in summary[0]:\n",
    "    if feat == 'params':\n",
    "        continue\n",
    "    allsummary[feat] = {}\n",
    "    for method in summary[0][feat]:\n",
    "        if method =='true':\n",
    "            continue\n",
    "        allsummary[feat][method] = {}\n",
    "        for attr in summary[0][feat][method]:\n",
    "            avg = np.mean([summary[t][feat][method][attr]\n",
    "                           for t in range(n_instances)])\n",
    "            std = np.std([summary[t][feat][method][attr]\n",
    "                          for t in range(n_instances)])\n",
    "            stderr = std / np.sqrt(n_instances)\n",
    "            allsummary[feat][method][attr] = \"{:.3f} +/- {:.3f}\".format(avg, 1.96 * stderr)\n",
    "\n",
    "allsummary['params'] = {}\n",
    "for period in summary[0]['params']:\n",
    "    allsummary['params'][period] = {}\n",
    "    for feat in summary[0]['params'][period]:\n",
    "        allsummary['params'][period][feat] = {}\n",
    "        for method in summary[0]['params'][period][feat]:\n",
    "            if method =='true':\n",
    "                continue\n",
    "            allsummary['params'][period][feat][method] = {}\n",
    "            for attr in summary[0]['params'][period][feat][method]:\n",
    "                avg = np.mean([summary[t]['params'][period][feat][method][attr]\n",
    "                               for t in range(n_instances)])\n",
    "                std = np.std([summary[t]['params'][period][feat][method][attr]\n",
    "                              for t in range(n_instances)])\n",
    "                stderr = std / np.sqrt(n_instances)\n",
    "                allsummary['params'][period][feat][method][attr] = \"{:.3f} +/- {:.3f}\".format(avg, 1.96 * stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
